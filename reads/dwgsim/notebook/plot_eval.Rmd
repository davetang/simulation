---
title: "Plot dwgsim_eval output"
author: "Dave Tang"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: false
    toc_float: false
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = FALSE)
# use with ggplot2, for example
# scale_fill_manual(values = cbPalette) +
# NULL
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
options(
  ggplot2.discrete.fill = cbPalette,
  ggplot2.discrete.colour = cbPalette
)

theme_set(theme_bw())
theme_update(
  legend.text = element_text(size = 20),
  legend.title = element_blank()
)
```

## Introduction

[DWGSIM](https://github.com/nh13/DWGSIM) was used to simulate reads to evaluate different mapping tools. In this notebook we explore the evaluation results generated by `dwgsim_eval`.

## Data

Create column vector based [on the documentation](https://github.com/nh13/DWGSIM/blob/main/docs/04_Evaluating_Mappings.md).

The `dwgsim_eval` tool outputs a table with the following columns:

| Number | Column | Description |
| ------ | ------ | ----------- |
|    1   |  `thr` | The alignment threshold (see `-a`) |
|    2   |  `mc`  | The number of reads mapped correctly that should be mapped at the threshold |
|    3   |  `mi`  | The number of reads mapped incorrectly that should be mapped be mapped at the threshold |
|    4   |  `mu`  | The number of reads unmapped that should be mapped be mapped at the threshold |
|    5   |  `um`  | The number of reads mapped that should be unmapped be mapped at the threshold |
|    6   |  `uu`  | The number of reads unmapped that should be unmapped be mapped at the threshold |
|    7   |  `mc + mi + mu + um + uu` | The total number of reads that should be unmapped be mapped at the threshold |
|    8   |  `mc'` | The number of reads mapped correctly that should be mapped at or greater than the threshold |
|    9   |  `mi'` | The number of reads mapped incorrectly that should be mapped be mapped at or greater than the threshold |
|   10   |  `mu'` | The number of reads unmapped that should be mapped be mapped at or greater than the threshold |
|   11   |  `um'` | The number of reads mapped that should be unmapped be mapped at or greater than the threshold |
|   12   |  `uu'` | The number of reads unmapped that should be unmapped be mapped at or greater than the threshold |
|   13   |  `mc' + mi' + mu' + um' + uu'` | The total number of reads that should be unmapped be mapped at or greater than the threshold |
|   14   |  `mc / (mc + mi + mu)` | Sensitivity at the threshold. I.e. the fraction of reads that should be mapped that are mapped correctly. |
|   15   |  `mc / (mc + mi)` | Positive predictive value at the threshold. I.e. The fraction of mapped reads that are mapped correctly. |
|   16   |  `um / (um + uu)` | False discovery rate at the threshold.  I.e. The fraction of random reads that are mapped. |
|   17   |  `mc' / (mc' + mi' + mu')` | Sensitivity at or greater than the threshold. I.e. the fraction of reads that should be mapped that are mapped correctly. |
|   18   |  `mc' / (mc' + mi')` | Positive predictive value at or greater than the threshold. I.e. The fraction of mapped reads that are mapped correctly. |
|   19   |  `um' / (um' + uu')` | False discovery rate at or greater than the threshold.  I.e. The fraction of random reads that are mapped. |

"At or greater than the threshold" tells us what our sensitivity, PPV, and FDR would be if we filtered based on that threshold.

```{r col_spec}
my_cols <- c(
  'mq', 'mc', 'mi', 'mu', 'um', 'uu', 'mt',
  'mct', 'mit', 'mut', 'umt', 'uut', 'mtt',
  'recall', 'ppv', 'fdr',
  'recallt', 'ppvt', 'fdrt'
)

my_col_types <- cols(
  'i', 'i', 'i', 'i', 'i', 'i', 'i',
  'i', 'i', 'i', 'i', 'i', 'i',
  'd', 'd', 'd',
  'd', 'd', 'd'
)
```

Results stored in `test`.

```{r list_files}
list.files(path = "../test", pattern = "^dwgsim")
```

The directory name contains the arguments used to run `dwgsim`:

    dwgsim_$(PREFIX)_$(N)_$(READ_LEN)_$(ERROR_RATE)_$(MUT_RATE)_$(INDEL_RATE)_$(INDEL_EXT)_$(RAND_PROB)_$(SEED)
    
```{r get_args}
get_args <- function(x){
  params <- c(
    'tool',
    'genome',
    'reads', 
    'read_length',
    'error_rate',
    'mutation_rate',
    'indel_rate',
    'indel_ext_rate',
    'random_read_prob',
    'seed'
  )
  args <- str_split(string = basename(x), pattern = "_")[[1]]
  names(args) <- params
  as.list(args)
}
```

Functions to load results.

`dwgsim_eval` can also output incorrect alignments (SAM output) with the `-p` option. Incorrect alignments were subtracted from all alignments using `bam_subtract.py` to create a correct alignment BAM file. These BAM files are summarised using `bam_summary.py` and we will load these results below.

```{r result_functions}
my_tools <- c('bwa', 'mm', 'dr')
load_res <- function(my_dir, my_set = "all", suffix = ".eval.txt.gz"){
  my_tib <- tibble()
  for (tool in my_tools){
    assign(
      x = tool,
      value = read_table(
        paste0(my_dir, "/hg38.", tool, suffix),
        comment = "#",
        col_names = my_cols,
        col_types = my_col_types
      ) %>%
        mutate(tool = tool) %>%
        mutate(var = my_set) %>%
        dplyr::select(mq, tool, var, everything())
    )
    my_tib <- rbind(my_tib, get(tool))
  }
  return(my_tib)
}

load_bam_summary <- function(my_dir, my_set = "correct", suffix = ".correct.tsv"){
  my_tib <- tibble()
  for (tool in my_tools){
    assign(
      x = tool,
      value = read_table(
        paste0(my_dir, "/hg38.", tool, suffix),
        comment = "#",
        col_types = cols('c', 'i', 'i', 'i', 'i')
      ) %>%
        mutate(tool = tool) %>%
        mutate(set = my_set) %>%
        dplyr::select(tool, set, everything())
    )
    my_tib <- rbind(my_tib, get(tool))
  }
  return(my_tib)
}
```

Load evaluation result.

```{r load_eval}
sims <- list.files(path = "../test", pattern = "^dwgsim", full.names = TRUE)
res <- list(list(dir = basename(sim)))
for (i in 1:length(sims)){
  res[[i]]$params <- get_args(sims[i])
  res[[i]]$metrics <- rbind(
    load_res(sims[i]),
    load_res(sims[i], "indels", ".indels.eval.txt.gz")
  )
  res[[i]]$metrics$tool <- factor(res[[i]]$metrics$tool)
  res[[i]]$read_metrics <- rbind(
    load_bam_summary(sims[i]),
    load_bam_summary(sims[1], "incorrect", ".incorrect.tsv")
  )
}
```

Check out the metrics data frame.

```{r check_metrics}
res[[1]]$metrics %>%
  filter(tool == "dr")
```

Check out the read metrics data frame.

```{r check_metrics}
res[[1]]$read_metrics %>%
  filter(tool == "dr")
```

## Results

### Mapping

Accuracy.

```{r accuracy}
res[[1]]$metrics %>%
  group_by(tool, var) %>%
  summarise(total_read = sum(mt), accuracy = sum(mc)/sum(mt))
```

Mapped total.

```{r mapped_tool}
res[[1]]$metrics %>%
  group_by(tool, var) %>%
  summarise(total_read = sum(mt))
```

Accuracy without mapping quality zero.

```{r accuracy_no_mapq_zero}
res[[1]]$metrics %>%
  filter(mq > 0) %>%
  group_by(tool, var) %>%
  summarise(total_read = sum(mt), accuracy = sum(mc)/sum(mt))
```

Plot total mapped at different mapping qualities.

```{r mapped_total_by_mq, fig.width=8, fig.height=4}
ggplot(res[[1]]$metrics, aes(mq, mt, fill = tool)) +
  geom_bar(stat = "identity", position = "dodge2") +
  facet_wrap(~var, scales = "free") +
  NULL
```

Plot mapped incorrectly at different mapping qualities.

```{r mapped_incorrectly_by_mq, fig.width=7, fig.height=4}
ggplot(res[[1]]$metrics, aes(mq, mi, fill = tool)) +
  geom_bar(stat = "identity", position = "dodge2") +
  facet_wrap(~var, scales = "free") +
  NULL
```

Plot percentage mapped correctly at different mapping qualities.

```{r percent_correct_by_mq, fig.width=7, fig.height=5}
ggplot(res[[1]]$metrics, aes(mq, mc/mt*100, colour = tool)) +
  geom_point() +
  geom_line() +
  ylim(c(0, 100)) +
  facet_grid(~var) +
  theme(
    legend.text = element_text(size = 20),
    legend.title = element_blank()
  )
```

Sensitivity at or greater than the threshold, i.e. the fraction of reads that should be mapped that are mapped correctly.

```{r recallt, fig.width=6, fig.height=4}
ggplot(res[[1]]$metrics, aes(mq, recallt, colour = tool)) +
  geom_line() +
  facet_grid(~var)
```

Positive predictive value at or greater than the threshold, i.e. The fraction of mapped reads that are mapped correctly.

```{r ppv, fig.width=7, fig.height=5}
ggplot(res[[1]]$metrics, aes(mq, ppvt, colour = tool)) +
  geom_point() +
  geom_line() +
  facet_grid(~var)
```

False discovery rate at or greater than the threshold, i.e. the fraction of random reads that are mapped.

```{r fdrt, fig.width=7, fig.height=5}
ggplot(res[[1]]$metrics, aes(mq, fdrt, colour = tool)) +
  geom_line() +
  facet_grid(~var)
```
